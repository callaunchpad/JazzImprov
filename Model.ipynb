{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.  ,  2.  ,  4.25,  3.  ],\n",
       "       [21.  ,  3.  ,  1.  ,  2.  ],\n",
       "       [17.  ,  4.  ,  3.25, -3.  ],\n",
       "       [22.  ,  5.  ,  6.75, -4.  ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get data from grammar's csv file of a single type format\n",
    "cluster_info = np.loadtxt(open(\"test_files/test.csv\", \"r\"), delimiter=\",\", skiprows=1)\n",
    "cluster_info\n",
    "#at what index is the s-expression id in this? once we know this, we can add the s-expression id to each node's lsit of s-expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "k_size = int(len(cluster_info)/2) #k_size is arbitrarily set, equal to the number of clusters\n",
    "print(k_size)\n",
    "kmeans = KMeans(n_clusters=k_size).fit(cluster_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#outputs which cluster number the data point is placed into\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kmeans.predict(fill in with our own 7 unit vector data), will classify it into cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, node_num):\n",
    "        self.node_num = node_num\n",
    "        self.s_exp = [] #list of s-exp-ids\n",
    "        self.cpt = {} #maps from node_num to conditional probability\n",
    "        self.count = 0\n",
    "    \n",
    "    def add_exp(self, s):\n",
    "        self.s_exp.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s-exp</th>\n",
       "      <th>song-id</th>\n",
       "      <th>song-index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asdf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gdnk</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hjkl</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sifn</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>husk</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>slei</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wert</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  s-exp  song-id  song-index\n",
       "0  asdf        1           1\n",
       "1  gdnk        1           2\n",
       "2  hjkl        1           3\n",
       "3  sifn        1           4\n",
       "4  husk        2           1\n",
       "5  slei        2           2\n",
       "6  wert        3           1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dictionary that maps s-exp-id to: s-exp, song-id (which song), song-index (position in song)\n",
    "s_exp_dict = {} \n",
    "\n",
    "#assume s_exp_labels is grammar output with 3 columns: s-exp, song-id, song-index\n",
    "#s_exp_labels = np.loadtxt(open(\"test_files/test_exp.csv\", \"r\"), dtype=\"str\", delimiter=\",\", skiprows=1)\n",
    "s_exp_labels = pd.read_csv('test_files/test_exp.csv')\n",
    "s_exp_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['asdf', 1, 1],\n",
       " 1: ['gdnk', 1, 2],\n",
       " 2: ['hjkl', 1, 3],\n",
       " 3: ['sifn', 1, 4],\n",
       " 4: ['husk', 2, 1],\n",
       " 5: ['slei', 2, 2],\n",
       " 6: ['wert', 3, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for expression in s_exp_labels:\n",
    "#     s_exp_dict[expression[0]] = [expression[1], expression[2], expression[3]]\n",
    "for index, row in s_exp_labels.iterrows():\n",
    "    s_exp_dict[index] = [row['s-exp'], row['song-id'], row['song-index']]\n",
    "\n",
    "s_exp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "node_objects = [] #list of nodes for the Markov chain\n",
    "\n",
    "for cluster_num in range(k_size):\n",
    "    node_objects.append(Node(cluster_num)) #initialize 1 node for each cluster number\n",
    "    \n",
    "for i in range(0,len(kmeans.labels_)): #iterating through all the data points\n",
    "    cluster_num = kmeans.labels_[i] #access the cluster num each data point corresponds to\n",
    "    #adding s-exp, song-id (which song), song-index (position in song) to the node object\n",
    "    node_objects[cluster_num].add_exp(s_exp_dict[i]) #why string??? (previously)\n",
    "    # find how to add the s-expression id correspondng to that node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0ad4d0496b0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ms_expression_outer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mouter_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_exp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0ms_expression_inner\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minner_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms_exp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0ms_exp_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms_expression_outer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ms_exp_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms_expression_inner\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms_exp_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms_expression_inner\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms_exp_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms_expression_outer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m                     \u001b[0mouter_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mouter_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minner_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "#create cpt\n",
    "for outer_node in node_objects:\n",
    "    for inner_node in node_objects:\n",
    "        outer_node.cpt[inner_node.node_num] = 0\n",
    "        #if (outer_node != inner_node):\n",
    "        for s_expression_outer in outer_node.s_exp:\n",
    "            for s_expression_inner in inner_node.s_exp:\n",
    "                if s_exp_dict[s_expression_outer][1] == s_exp_dict[s_expression_inner][1] and s_exp_dict[s_expression_inner][2] - s_exp_dict[s_expression_outer][2] == 1:\n",
    "                    outer_node.count += 1\n",
    "                    outer_node.cpt[inner_node.node_num] += 1\n",
    "    #creates the probability of going to the next node, not s-exp\n",
    "    outer_node.cpt = {k:v/outer_node.count for k, v in outer_node.cpt.items() if outer_node.count != 0} \n",
    "print(outer_node.cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
