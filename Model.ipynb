{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[25.  ,  2.  ,  4.25,  3.  ],\n",
       "       [21.  ,  3.  ,  1.  ,  2.  ],\n",
       "       [17.  ,  4.  ,  3.25, -3.  ],\n",
       "       [22.  ,  5.  ,  6.75, -4.  ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get data from grammar's csv file of a single type format\n",
    "cluster_info = np.loadtxt(open(\"test_files/test.csv\", \"r\"), delimiter=\",\", skiprows=1)\n",
    "cluster_info\n",
    "#at what index is the s-expression id in this? once we know this, we can add the s-expression id to each node's lsit of s-expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "k_size = int(len(cluster_info)/2) #k_size is arbitrarily set, equal to the number of clusters\n",
    "print(k_size)\n",
    "kmeans = KMeans(n_clusters=k_size).fit(cluster_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#outputs which cluster number the data point is placed into\n",
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kmeans.predict(fill in with our own 7 unit vector data), will classify it into cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, node_num):\n",
    "        self.node_num = node_num\n",
    "        self.s_exp = [] #list of s-exp-ids\n",
    "        self.cpt = {} #maps from node_num to conditional probability\n",
    "        self.count = 0\n",
    "    \n",
    "    def add_exp(self, s):\n",
    "        self.s_exp.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s-exp</th>\n",
       "      <th>song-id</th>\n",
       "      <th>song-index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>asdf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gdnk</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hjkl</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sifn</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>husk</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>slei</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>wert</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  s-exp  song-id  song-index\n",
       "0  asdf        1           1\n",
       "1  gdnk        1           2\n",
       "2  hjkl        1           3\n",
       "3  sifn        1           4\n",
       "4  husk        2           1\n",
       "5  slei        2           2\n",
       "6  wert        3           1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dictionary that maps s-exp-id to: s-exp, song-id (which song), song-index (position in song)\n",
    "s_exp_dict = {} \n",
    "\n",
    "#assume s_exp_labels is grammar output with 3 columns: s-exp, song-id, song-index\n",
    "#s_exp_labels = np.loadtxt(open(\"test_files/test_exp.csv\", \"r\"), dtype=\"str\", delimiter=\",\", skiprows=1)\n",
    "s_exp_labels = pd.read_csv('test_files/test_exp.csv')\n",
    "s_exp_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['asdf', 1, 1],\n",
       " 1: ['gdnk', 1, 2],\n",
       " 2: ['hjkl', 1, 3],\n",
       " 3: ['sifn', 1, 4],\n",
       " 4: ['husk', 2, 1],\n",
       " 5: ['slei', 2, 2],\n",
       " 6: ['wert', 3, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for expression in s_exp_labels:\n",
    "#     s_exp_dict[expression[0]] = [expression[1], expression[2], expression[3]]\n",
    "for index, row in s_exp_labels.iterrows():\n",
    "    s_exp_dict[index] = [row['s-exp'], row['song-id'], row['song-index']]\n",
    "\n",
    "s_exp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_objects = [] #list of nodes for the Markov chain\n",
    "\n",
    "for cluster_num in range(k_size):\n",
    "    node_objects.append(Node(cluster_num)) #initialize 1 node for each cluster number\n",
    "    \n",
    "for i in range(0,len(kmeans.labels_)): #iterating through all the data points\n",
    "    cluster_num = kmeans.labels_[i] #access the cluster num each data point corresponds to\n",
    "    #adding s-exp, song-id (which song), song-index (position in song) to the node object\n",
    "    node_objects[cluster_num].add_exp(cluster_info[i][0]) #why string??? (previously)\n",
    "    # find how to add the s-expression id correspondng to that node\n",
    "    # index 0 is s-expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "17.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8408356aa68e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0;31m#print(s_expression_outer)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0;31m#print(s_exp_dict)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0ms_exp_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms_expression_outer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ms_exp_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms_expression_inner\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms_exp_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms_expression_inner\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ms_exp_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms_expression_outer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m                     \u001b[0mouter_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                     \u001b[0mouter_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minner_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_num\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 17.0"
     ]
    }
   ],
   "source": [
    "#create cpt\n",
    "for outer_node in node_objects:\n",
    "    for inner_node in node_objects:\n",
    "        outer_node.cpt[inner_node.node_num] = 0\n",
    "        #if (outer_node != inner_node):\n",
    "        for s_expression_outer in outer_node.s_exp:\n",
    "            for s_expression_inner in inner_node.s_exp:\n",
    "                #print(s_expression_outer)\n",
    "                #print(s_exp_dict)\n",
    "                if s_exp_dict[s_expression_outer][1] == s_exp_dict[s_expression_inner][1] and (s_exp_dict[s_expression_inner][2] - s_exp_dict[s_expression_outer][2] == 1):\n",
    "                    outer_node.count += 1\n",
    "                    outer_node.cpt[inner_node.node_num] += 1\n",
    "    #creates the probability of going to the next node, not s-exp\n",
    "    outer_node.cpt = {k:v/outer_node.count for k, v in outer_node.cpt.items() if outer_node.count != 0} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weighted_random_by_dct(dct):\n",
    "   rand_val = random.random() #random value between 0 and 1\n",
    "   total = 0\n",
    "   for k, v in dct.items():\n",
    "       total += v\n",
    "       if rand_val <= total: #if running total exceeds probability, that's what you want\n",
    "           return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes in a number and returns list of s-exp ids generated by the cpt ordering given by probabilities\n",
    "#cpt jumps from s-exp to s-exp\n",
    "#nodes are collection of s-exp (s-exp is 1 measure with all those features)\n",
    "def s_expressions(n): #n is length of \n",
    "    s_exp_ids = [] #create empty list\n",
    "    start = int(random.uniform(0, len(node_objects))) #random start node\n",
    "    next_node = node_objects[start] #get that node\n",
    "    for i in range(n):\n",
    "        next_node_num = weighted_random_by_dct(next_node.cpt) #get the next node based on the current node's cpt\n",
    "        print(next_node_num)\n",
    "        next_node = node_objects[next_node_num] #set the next node variable to that node\n",
    "        next_s_exp_id = random.choice(next_node.s_exp) #get a random s-expression in that node \n",
    "        s_exp_ids += [next_s_exp_id] #store id in the list\n",
    "    return s_exp_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#go from s-exp to producing actual notes by calling possible_notes which passes into select_note\n",
    "def produce_notes(num_of_measures, list_of_chords): #length of chords list = num of measures\n",
    "    notes_df = pd.DataFrame(columns=[\"note\", \"start_time\", \"duration\"])\n",
    "    s_exp_ids = s_expressions(num_of_measures)\n",
    "    for i in range(num_of_measures): #i refers to measure number\n",
    "        s_exp = s_exp_dict[s_exp_ids[i]][0] #ith s-exp, which is a string\n",
    "        split_list = s_exp.split(\" \")\n",
    "        curr_note = \"Bb4\" #figure out how to start the curr_note initially\n",
    "        min_slope = split_list[0]\n",
    "        max_slope = split_list[1]\n",
    "        for j in range(2, len(split_list)):\n",
    "            category = split_list[j].split(\"|\")[0]\n",
    "            start = split_list[j].split(\"|\")[1]\n",
    "            duration = split_list[j].split(\"|\")[2]\n",
    "            #possible_notes is looking at which other notes match note and category\n",
    "            poss_notes_list = possible_notes(list_of_chords[i], category)\n",
    "            selected_note = select_note(poss_notes_list, curr_note, min_slope, max_slope)\n",
    "            notes_df.loc[j-2] = [selected_note, start+i, duration]\n",
    "            curr_note = selected_note\n",
    "notes_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
